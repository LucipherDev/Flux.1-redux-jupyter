{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Install</h1></center>\n",
        "\n",
        "%cd /content\n",
        "!git clone -b totoro6 https://github.com/LucipherDev/ComfyUI /content/TotoroUI\n",
        "!git clone -b totoro https://github.com/LucipherDev/ComfyUI_AdvancedRefluxControl /content/TotoroUI/custom_nodes/TotoroUI_AdvancedRefluxControl\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.28.post2\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "import nodes\n",
        "\n",
        "if not nodes.load_custom_node(\"custom_nodes/TotoroUI_AdvancedRefluxControl\"):\n",
        "  raise Exception(\"Failed to load Advanced Redux custom node\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3aTOrdb8HxC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Load Models</h1></center>\n",
        "\n",
        "import torch\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "\n",
        "DualCLIPLoader = NODE_CLASS_MAPPINGS[\"DualCLIPLoader\"]()\n",
        "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "CLIPVisionLoader = NODE_CLASS_MAPPINGS[\"CLIPVisionLoader\"]()\n",
        "StyleModelLoader = NODE_CLASS_MAPPINGS[\"StyleModelLoader\"]()\n",
        "\n",
        "flux_version = \"dev\" # @param [\"dev\",\"schnell\"]\n",
        "\n",
        "print(f\"Downloading Flux.1-{flux_version}...\")\n",
        "\n",
        "if flux_version == \"schnell\":\n",
        "  !aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors -d /content/TotoroUI/models/unet -o flux1-schnell.safetensors\n",
        "elif flux_version == \"dev\":\n",
        "  !aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-dev-fp8.safetensors -d /content/TotoroUI/models/unet -o flux1-dev.safetensors\n",
        "\n",
        "print(\"Downloading VAE...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/TotoroUI/models/vae -o ae.sft\n",
        "\n",
        "print(\"Downloading Clips...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /content/TotoroUI/models/clip -o clip_l.safetensors\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp8_e4m3fn.safetensors -d /content/TotoroUI/models/clip -o t5xxl_fp8_e4m3fn.safetensors\n",
        "\n",
        "print(\"Downloading Clip Vision...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/sigclip_vision_384/resolve/main/sigclip_vision_patch14_384.safetensors -d /content/TotoroUI/models/clip_vision -o sigclip_vision_patch14_384.safetensors\n",
        "\n",
        "print(\"Downloading Flux.1-Redux-dev...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/second-state/FLUX.1-Redux-dev-GGUF/resolve/main/flux1-redux-dev.safetensors -d /content/TotoroUI/models/style_models -o flux1-redux-dev.safetensors\n",
        "\n",
        "with torch.inference_mode():\n",
        "    print(\"Loading VAE...\")\n",
        "    vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
        "    print(f\"Loading Flux.1-{flux_version}...\")\n",
        "    unet = UNETLoader.load_unet(f\"flux1-{flux_version}.safetensors\", \"fp8_e4m3fn\")[0]\n",
        "    print(\"Loading Clips...\")\n",
        "    clip = DualCLIPLoader.load_clip(\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\")[0]\n",
        "    print(\"Loading Clip Vision...\")\n",
        "    clip_vision = CLIPVisionLoader.load_clip(\"sigclip_vision_patch14_384.safetensors\")[0]\n",
        "    print(\"Loading Style Model...\")\n",
        "    style_model = StyleModelLoader.load_style_model(\"flux1-redux-dev.safetensors\")[0]\n",
        "\n",
        "print(\"All Models Loaded!\")\n",
        "\n",
        "import re\n",
        "import os\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "from google.colab import files, output\n",
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "from PIL import Image, ImageOps\n",
        "import io\n",
        "import random\n",
        "\n",
        "import nodes\n",
        "from totoro_extras import nodes_custom_sampler\n",
        "from totoro_extras import nodes_post_processing\n",
        "from totoro_extras import nodes_flux\n",
        "from totoro_extras import nodes_mask\n",
        "from totoro import model_management\n",
        "\n",
        "CLIPTextEncodeFlux = nodes_flux.NODE_CLASS_MAPPINGS[\"CLIPTextEncodeFlux\"]()\n",
        "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "VAEEncode = NODE_CLASS_MAPPINGS[\"VAEEncode\"]()\n",
        "ImageToMask = nodes_mask.NODE_CLASS_MAPPINGS[\"ImageToMask\"]()\n",
        "MaskToImage = nodes_mask.NODE_CLASS_MAPPINGS[\"MaskToImage\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "ReduxAdvanced = NODE_CLASS_MAPPINGS[\"ReduxAdvanced\"]()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLGPKWvopwnC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " # @markdown <ul><li><h2>Load Flux Redux</h2></li></ul>\n",
        "\n",
        "enable_image_1 = True # @param {\"type\":\"boolean\"}\n",
        "input_image_1 = \"/content/test.png\" # @param {\"type\":\"string\"}\n",
        "enable_image_2 = False # @param {\"type\":\"boolean\"}\n",
        "input_image_2 = \"/content/test.png\" # @param {\"type\":\"string\"}\n",
        "enable_image_3 = False # @param {\"type\":\"boolean\"}\n",
        "input_image_3 = \"/content/test.png\" # @param {\"type\":\"string\"}\n",
        "downsampling_function = \"area\" # @param [\"nearest\",\"bilinear\",\"bicubic\",\"area\",\"nearest-exact\"]\n",
        "resize_mode = \"autocrop with mask\" # @param [\"center crop (square)\",\"keep aspect ratio\",\"autocrop with mask\"]\n",
        "\n",
        "input_images = {\n",
        "    1: [enable_image_1, input_image_1, None, 3, 1.0],\n",
        "    2: [enable_image_2, input_image_2, None, 3, 1.0],\n",
        "    3: [enable_image_3, input_image_3, None, 3, 1.0]\n",
        "}\n",
        "\n",
        "interface = \"\"\"\n",
        "<div class=\"toolbar\">\n",
        "  <button class=\"toolbtn{tabId} button active\" id=\"drawButton{tabId}\" onclick=\"setTool{tabId}('draw')\"><i class=\"fa fa-paint-brush\"></i> Draw</button>\n",
        "  <button class=\"toolbtn{tabId} button\" id=\"eraseButton{tabId}\" onclick=\"setTool{tabId}('erase')\"><i class=\"fa fa-eraser\"></i> Erase</button>\n",
        "  <button class=\"toolbtn{tabId} button\" id=\"clearButton{tabId}\" onclick=\"clearCanvas{tabId}()\"><i class=\"fa fa-trash\"></i> Clear</button>\n",
        "  <button class=\"toolbtn{tabId} button\" id=\"saveButton{tabId}\" onclick=\"saveCanvas{tabId}()\"><i class=\"fa fa-check\"></i> Save</button>\n",
        "  <button class=\"toolbtn{tabId} button\" id=\"undoButton{tabId}\" onclick=\"undo{tabId}()\" disabled><i class=\"fa fa-undo\"></i></button>\n",
        "  <button class=\"toolbtn{tabId} button\" id=\"redoButton{tabId}\" onclick=\"redo{tabId}()\" disabled><i class=\"fa fa-rotate-right\"></i></button>\n",
        "  <div class=\"slider-container\">\n",
        "    <label for=\"brushSizeSlider{tabId}\">Brush Size: <span id=\"brushSizeDisplay{tabId}\">20</span></label>\n",
        "    <input class=\"slider\" id=\"brushSizeSlider{tabId}\" type=\"range\" min=\"1\" max=\"100\" value=\"20\">\n",
        "  </div>\n",
        "  <div class=\"slider-container\">\n",
        "    <label for=\"downsamplingFactorSlider{tabId}\">Downsampling Factor: <span id=\"downsamplingFactorDisplay{tabId}\">3</span></label>\n",
        "    <input class=\"slider\" id=\"downsamplingFactorSlider{tabId}\" type=\"range\" min=\"1\" max=\"9\" value=\"3\">\n",
        "  </div>\n",
        "  <div class=\"slider-container\">\n",
        "    <label for=\"weightSlider{tabId}\">Weight: <span id=\"weightDisplay{tabId}\">1</span></label>\n",
        "    <input class=\"slider\" id=\"weightSlider{tabId}\" type=\"range\" min=\"0\" max=\"1\" value=\"1\" step=\"0.01\">\n",
        "  </div>\n",
        "  <div class=\"checkbox-container\">\n",
        "    <label for=\"useMask{tabId}\">Use Mask</label>\n",
        "    <input class=\"use-mask\" type=\"checkbox\" id=\"useMask{tabId}\">\n",
        "  </div>\n",
        "</div>\n",
        "<div class=\"canvas-container\" id=\"canvasContainer{tabId}\">\n",
        "  <img class=\"image-overlay\" id=\"imageOverlay{tabId}\" />\n",
        "  <canvas id=\"paintCanvas{tabId}\"></canvas>\n",
        "</div>\n",
        "<script>\n",
        "const canvas{tabId}=document.getElementById('paintCanvas{tabId}');const ctx{tabId}=canvas{tabId}.getContext('2d');const imageOverlay{tabId}=document.getElementById('imageOverlay{tabId}');const canvasContainer{tabId}=document.getElementById('canvasContainer{tabId}');const brushSizeSlider{tabId}=document.getElementById('brushSizeSlider{tabId}');const brushSizeDisplay{tabId}=document.getElementById('brushSizeDisplay{tabId}');const downsamplingFactorSlider{tabId}=document.getElementById('downsamplingFactorSlider{tabId}');const downsamplingFactorDisplay{tabId}=document.getElementById('downsamplingFactorDisplay{tabId}');const weightSlider{tabId}=document.getElementById('weightSlider{tabId}');const weightDisplay{tabId}=document.getElementById('weightDisplay{tabId}');let tool{tabId}='draw';let drawing{tabId}=!1;let brushSize{tabId}=20;downsamplingFactor{tabId}=3;let weight{tabId}=1;function highlightActiveButton{tabId}(tool{tabId}){{document.querySelectorAll('.toolbtn{tabId}').forEach(button=>button.classList.remove('active'));if(tool{tabId}==='draw'){{document.getElementById('drawButton{tabId}').classList.add('active')}}else if(tool{tabId}==='erase'){{document.getElementById('eraseButton{tabId}').classList.add('active')}}}}\n",
        "const backgroundImage{tabId}=new Image();backgroundImage{tabId}.src=\"/files/{input_image}\";backgroundImage{tabId}.onload=function(){{const aspectRatio=backgroundImage{tabId}.width/backgroundImage{tabId}.height;let width,height;if(backgroundImage{tabId}.width>backgroundImage{tabId}.height){{height=512;width=height*aspectRatio}}else{{width=512;height=width/aspectRatio}}\n",
        "canvas{tabId}.width=width;canvas{tabId}.height=height;imageOverlay{tabId}.width=width;imageOverlay{tabId}.height=height;canvasContainer{tabId}.style.width=`${{width}}px`;canvasContainer{tabId}.style.height=`${{height}}px`;ctx{tabId}.fillStyle='black';ctx{tabId}.fillRect(0,0,canvas{tabId}.width,canvas{tabId}.height);imageOverlay{tabId}.src=backgroundImage{tabId}.src}};brushSizeSlider{tabId}.addEventListener('input',function(event){{brushSize{tabId}=event.target.value;brushSizeDisplay{tabId}.textContent=brushSize{tabId}}});downsamplingFactorSlider{tabId}.addEventListener('input',function(event){{downsamplingFactor{tabId}=event.target.value;downsamplingFactorDisplay{tabId}.textContent=downsamplingFactor{tabId}}});weightSlider{tabId}.addEventListener('input',function(event){{weight{tabId}=event.target.value;weightDisplay{tabId}.textContent=weight{tabId}}});function setTool{tabId}(selectedTool){{tool{tabId}=selectedTool;highlightActiveButton{tabId}(tool{tabId})}}\n",
        "canvas{tabId}.addEventListener('mousedown',()=>{{drawing{tabId}=!0}});canvas{tabId}.addEventListener('mouseup',()=>{{drawing{tabId}=!1;ctx{tabId}.beginPath()}});canvas{tabId}.addEventListener('mousemove',draw{tabId});function draw{tabId}(event){{if(!drawing{tabId})return;const rect=canvas{tabId}.getBoundingClientRect();const x=event.clientX-rect.left;const y=event.clientY-rect.top;ctx{tabId}.lineWidth=brushSize{tabId};ctx{tabId}.lineCap='round';ctx{tabId}.globalCompositeOperation='source-over';if(tool{tabId}==='draw'){{ctx{tabId}.strokeStyle='white'}}else if(tool{tabId}==='erase'){{ctx{tabId}.strokeStyle='black'}}\n",
        "ctx{tabId}.lineTo(x,y);ctx{tabId}.stroke();ctx{tabId}.beginPath();ctx{tabId}.moveTo(x,y)}}\n",
        "function clearCanvas{tabId}(){{ctx{tabId}.globalCompositeOperation='source-over';ctx{tabId}.fillStyle='black';ctx{tabId}.fillRect(0,0,canvas{tabId}.width,canvas{tabId}.height);ctx{tabId}.beginPath()}}\n",
        "function saveCanvas{tabId}(){{const dataURL=canvas{tabId}.toDataURL('image/png');google.colab.kernel.invokeFunction('notebook.save_mask',[{tabId},dataURL,downsamplingFactor{tabId},weight{tabId},document.getElementById('useMask{tabId}').checked],{{}})}}\n",
        "const undoStack{tabId}=[];const redoStack{tabId}=[];function updateUndoRedoButtons{tabId}(){{document.getElementById('undoButton{tabId}').disabled=undoStack{tabId}.length===0;document.getElementById('redoButton{tabId}').disabled=redoStack{tabId}.length===0}}\n",
        "function saveState{tabId}(){{undoStack{tabId}.push(canvas{tabId}.toDataURL());redoStack{tabId}.length=0;updateUndoRedoButtons{tabId}()}}\n",
        "function undo{tabId}(){{if(undoStack{tabId}.length===0)return;redoStack{tabId}.push(canvas{tabId}.toDataURL());const previousState{tabId}=undoStack{tabId}.pop();const img=new Image();img.src=previousState{tabId};img.onload=function(){{ctx{tabId}.clearRect(0,0,canvas{tabId}.width,canvas{tabId}.height);ctx{tabId}.drawImage(img,0,0)}};updateUndoRedoButtons{tabId}()}}\n",
        "function redo{tabId}(){{if(redoStack{tabId}.length===0)return;undoStack{tabId}.push(canvas{tabId}.toDataURL());const nextState=redoStack{tabId}.pop();const img=new Image();img.src=nextState;img.onload=function(){{ctx{tabId}.clearRect(0,0,canvas{tabId}.width,canvas{tabId}.height);ctx{tabId}.drawImage(img,0,0)}};updateUndoRedoButtons{tabId}()}}\n",
        "canvas{tabId}.addEventListener('mousedown',()=>{{saveState{tabId}();drawing{tabId}=!0}});canvas{tabId}.addEventListener('mouseup',()=>{{drawing{tabId}=!1;ctx{tabId}.beginPath()}});updateUndoRedoButtons{tabId}()\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "paint_interface = f\"\"\"\n",
        "<style>@import url(https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css);.button,.toolbar{{padding:10px 15px}}body{{background-color:#2d2d2d;font-family:Arial,sans-serif;color:#fff;margin:0;display:flex;justify-content:center;align-items:center}}.output_subarea.output_html.rendered_html{{display:flex;justify-content:center;flex-direction:column;align-items:center}}.toolbar{{display:flex;flex-wrap:wrap;justify-content:center;align-items:center;margin:10px auto;background-color:#3c3f41;border-radius:8px;width:100%;max-width:512px;box-shadow:0 4px 10px rgba(0,0,0,.3)}}.button{{margin:5px;font-size:14px;cursor:pointer;border-radius:5px;color:#fff;background-color:#5e5e5e;border:none;font-weight:700;transition:.3s}}.button:hover{{background-color:#757575}}.button.active{{background-color:#fff7e0;color:#202124}}.button:disabled{{cursor:default;background-color:#a9a9a9}}.slider-container{{display:flex;align-items:center;margin:10px 0;justify-content:center}}.slider{{margin-left:25px;cursor:pointer;width:200px}}.canvas-container{{margin:20px auto;border:2px solid #5e5e5e;border-radius:8px;position:relative;display:inline-block;width:512px;height:512px}}canvas{{display:block;cursor:crosshair}}.image-overlay{{position:absolute;top:0;left:0;pointer-events:none;opacity:.5;z-index:0}}.tab-content{{display:none;padding:20px;border-radius:8px;width:100%;color:#fff}}.tab-content.active{{display:flex;flex-direction:column;justify-content:center;align-items:center}}.checkbox-container{{width:100%;display:flex;align-items:center}}.use-mask{{margin-left:5px;width:20px;height:20px}}</style>\n",
        "\n",
        "<div class=\"toolbar\">\n",
        "  {\"\".join('''<button class=\"tabtn button\" onclick=\"openTab('tab{id}')\">Image {id}</button>'''.format(id=key) for key, value in input_images.items() if value[0])}\n",
        "</div>\n",
        "\n",
        "{\"\".join('<div id=\"tab{id}\" class=\"tab-content\">'.format(id=key) + interface.format(input_image=value[1], tabId=str(key))  + '</div>' for key, value in input_images.items() if value[0])}\n",
        "\n",
        "<script>\n",
        "function openTab(tabId){{const tabs=document.querySelectorAll('.tab-content');tabs.forEach(tab=>tab.classList.remove('active'));const buttons=document.querySelectorAll('.tabtn');buttons.forEach(button=>button.classList.remove('active'));document.getElementById(tabId).classList.add('active');event.target.classList.add('active')}}\n",
        "document.querySelectorAll('.tabtn')[0].classList.add('active');document.querySelectorAll('.tab-content')[0].classList.add('active')\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def save_mask(tab_id, data_url, downsampling_factor, weight, use_mask):\n",
        "  global input_images\n",
        "\n",
        "  downsampling_factor = int(downsampling_factor)\n",
        "  weight = float(weight)\n",
        "  tab_id = int(tab_id)\n",
        "\n",
        "  if use_mask:\n",
        "    header, encoded = data_url.split(\",\", 1)\n",
        "    binary_data = base64.b64decode(encoded)\n",
        "    img = Image.open(io.BytesIO(binary_data))\n",
        "\n",
        "    mask_dir = f\"/content/redux_mask_{tab_id}_{''.join(str(random.randint(0, 9)) for _ in range(5))}.png\"\n",
        "    img.save(mask_dir)\n",
        "  else:\n",
        "    mask_dir = None\n",
        "\n",
        "  input_images[tab_id][2]= mask_dir\n",
        "  input_images[tab_id][3]= downsampling_factor\n",
        "  input_images[tab_id][4]= weight\n",
        "\n",
        "  print(f\"Input image {tab_id} {'with Mask' if use_mask else 'without mask'} ---> downsampling_factor: {downsampling_factor} | weight: {weight}\")\n",
        "\n",
        "def img_tensor_to_np(img_tensor):\n",
        "  img_tensor = img_tensor.clone() * 255.0\n",
        "  return img_tensor.squeeze().numpy().astype(np.uint8)\n",
        "\n",
        "def img_np_to_tensor(img_np_list):\n",
        "  return torch.from_numpy(img_np_list.astype(np.float32) / 255.0).unsqueeze(0)\n",
        "\n",
        "def load_mask(mask_dir, image):\n",
        "  image_np = img_tensor_to_np(image)\n",
        "  img = Image.fromarray(image_np)\n",
        "  mask_image = LoadImage.load_image(mask_dir)[0]\n",
        "  mask_np = img_tensor_to_np(mask_image)\n",
        "  mask_img = Image.fromarray(mask_np)\n",
        "  mask_img = mask_img.resize((img.width, img.height), Image.Resampling.LANCZOS)\n",
        "  mask_np = np.array(mask_img).astype(np.uint8)\n",
        "  mask_image = img_np_to_tensor(mask_np)\n",
        "\n",
        "  mask = ImageToMask.image_to_mask(mask_image, \"red\")[0]\n",
        "\n",
        "  return mask\n",
        "\n",
        "def apply_redux(cond):\n",
        "  for key, value in input_images.items():\n",
        "    if value[0]:\n",
        "      image = LoadImage.load_image(value[1])[0]\n",
        "      mask = load_mask(value[2], image) if value[2] else None\n",
        "      cond, image, mask = ReduxAdvanced.apply_stylemodel(clip_vision, image, style_model, cond, value[3], downsampling_function, \"keep aspect ratio\" if not value[2] and resize_mode == \"autocrop with mask\" else resize_mode, value[4], mask, 0.1)\n",
        "\n",
        "      display(HTML(f\"\"\"\n",
        "      <div style=\"display: flex; gap: 10px;\">\n",
        "          {\"\".join(f'<img src=\"data:image/png;base64,{base64.b64encode(io.BytesIO(Image.fromarray(img).save((buf:=io.BytesIO()), format=\"PNG\") or buf.getvalue()).getvalue()).decode(\"utf-8\")}\" style=\"width: 512px;\">' for img in [img_tensor_to_np(image), img_tensor_to_np(MaskToImage.mask_to_image(mask)[0])])}\n",
        "      </div>\n",
        "      \"\"\"))\n",
        "\n",
        "  return cond\n",
        "\n",
        "def cuda_gc():\n",
        "  try:\n",
        "    model_management.soft_empty_cache()\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "def save_image(decoded, path, name, download=False):\n",
        "  full_path = os.path.abspath(os.path.join(path, name))\n",
        "  Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save( full_path)\n",
        "\n",
        "  img = Image.open(full_path)\n",
        "  display(img)\n",
        "\n",
        "  if download:\n",
        "    files.download(full_path)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(prompt, width, height, fixed_seed, guidance, steps, sampler_name, scheduler, batch_size, auto_download):\n",
        "  print(\"Prompt Received\")\n",
        "\n",
        "  latent_image = EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16))[0]\n",
        "\n",
        "  cond = CLIPTextEncodeFlux.encode(clip, prompt, prompt, guidance)[0]\n",
        "  cond = apply_redux(cond)\n",
        "  guider = BasicGuider.get_guider(unet, cond)[0]\n",
        "  sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
        "  sigmas = BasicScheduler.get_sigmas(unet, scheduler, steps, 1.0)[0]\n",
        "\n",
        "  for i in range(0, batch_size):\n",
        "    if fixed_seed == 0:\n",
        "      seed = random.randint(0, 18446744073709551615)\n",
        "    else:\n",
        "      seed = fixed_seed\n",
        "\n",
        "    print(\"Seed:\", seed)\n",
        "\n",
        "    noise = RandomNoise.get_noise(seed)[0]\n",
        "    sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
        "    model_management.soft_empty_cache()\n",
        "    decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
        "\n",
        "    save_image(decoded, \"/content\", f\"flux_redux_{seed}_{i}.png\", auto_download)\n",
        "\n",
        "  cuda_gc()\n",
        "\n",
        "if any(ls[0] for ls in input_images.values()):\n",
        "  output.register_callback('notebook.save_mask', save_mask)\n",
        "  display(HTML(paint_interface))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ur9TmMNwC2kR"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Reflux</h1></center>\n",
        "\n",
        "positive_prompt = \"anime style\" # @param {\"type\":\"string\"}\n",
        "width = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "height = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "fixed_seed = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":18446744073709552000,\"step\":1}\n",
        "guidance = 3.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":20,\"step\":0.5}\n",
        "steps = 25 # @param {\"type\":\"slider\",\"min\":4,\"max\":50,\"step\":1}\n",
        "sampler_name = \"euler\" # @param [\"euler\",\"heun\",\"heunpp2\",\"heunpp2\",\"dpm_2\",\"lms\",\"dpmpp_2m\",\"ipndm\",\"deis\",\"ddim\",\"uni_pc\",\"uni_pc_bh2\"]\n",
        "scheduler = \"simple\" # @param [\"normal\",\"sgm_uniform\",\"simple\",\"ddim_uniform\"]\n",
        "batch_size = 1 # @param {\"type\":\"slider\",\"min\":1,\"max\":20,\"step\":1}\n",
        "auto_download = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "generate(positive_prompt, width, height, fixed_seed, guidance, steps, sampler_name, scheduler, batch_size, auto_download)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}